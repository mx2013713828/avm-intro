#include <gst/gst.h>
#include <gst/rtsp-server/rtsp-server.h>
#include <gst/app/gstappsrc.h>
#include <gst/app/gstappsink.h>
#include <glib.h>
#include <stdio.h>
#include <signal.h>
#include <chrono>
#include <vector>
#include <string>
#include <mutex>
#include <condition_variable>
#include <opencv2/opencv.hpp>
#include "nvbuffer_cuda_processor.h"

#ifdef HAVE_JETSON_NVMM
#include <nvbufsurface.h>
#endif

// --- é…ç½®å‚æ•° ---
static const char *DEFAULT_DEVICES[4] = {"/dev/video0", "/dev/video1", "/dev/video2", "/dev/video3"};
static const int IN_WIDTH = 1280;   // ROECS input width
static const int IN_HEIGHT = 1080;  // ROECS input height
static const int OUT_WIDTH = 1000;  // Stitching output width
static const int OUT_HEIGHT = 1000; // Stitching output height
static const int FPS = 30;

// --- å…¨å±€çŠ¶æ€ ---
static GMainLoop *main_loop = nullptr;
static gboolean is_simulation = FALSE;
static std::string dataset_path = "../ROECS_dataset/full_texture";
static int current_frame_idx = 204;
static const int START_FRAME = 204;
static const int END_FRAME = 303;

// æ˜¾å­˜èµ„æº
static uchar4* d_ins[4] = {nullptr}; // for Sim
static uchar4* d_out = nullptr;      // Common output buffer

// çº¿ç¨‹åŒæ­¥ (ç”¨äº Real Mode: Capture Thread -> RTSP Thread)
static std::mutex g_frame_mutex;
static std::condition_variable g_frame_cv;
static bool g_has_new_frame = false;
static std::chrono::high_resolution_clock::time_point g_capture_time;

// é‡‡é›†ç®¡çº¿ (Orin Only)
static GstElement *g_capture_pipeline = nullptr;

// --- ä¿¡å·å¤„ç† ---
static void signal_handler(int signum) {
    g_print("\nInterrupt signal (%d) received.\n", signum);
    if (main_loop) g_main_loop_quit(main_loop);
}

// =========================================================================
// æ¨¡å¼ A: ä»¿çœŸæ¨¡å¼ (è¯»å–æ–‡ä»¶)
// =========================================================================
static void process_simulation_frame() {
    char buf[256];
    const char* cam_names[] = {"F", "L", "B", "R"};
    std::vector<uchar4*> input_ptrs;

    for (int i = 0; i < 4; i++) {
        snprintf(buf, sizeof(buf), "%s/%06d %s.jpg", dataset_path.c_str(), current_frame_idx, cam_names[i]);
        cv::Mat img = cv::imread(buf);
        if (img.empty()) {
            current_frame_idx = START_FRAME; 
            snprintf(buf, sizeof(buf), "%s/%06d %s.jpg", dataset_path.c_str(), current_frame_idx, cam_names[i]);
            img = cv::imread(buf);
        }
        
        cv::Mat rgba;
        cv::cvtColor(img, rgba, cv::COLOR_BGR2RGBA);
        if (rgba.cols != IN_WIDTH || rgba.rows != IN_HEIGHT) cv::resize(rgba, rgba, cv::Size(IN_WIDTH, IN_HEIGHT));
        
        cudaMemcpy(d_ins[i], rgba.data, IN_WIDTH * IN_HEIGHT * sizeof(uchar4), cudaMemcpyHostToDevice);
        input_ptrs.push_back(d_ins[i]);
    }

    current_frame_idx++;
    if (current_frame_idx > END_FRAME) current_frame_idx = START_FRAME;

    auto start = std::chrono::high_resolution_clock::now();
    stitching_process(d_out, OUT_WIDTH * sizeof(uchar4), input_ptrs);
    cudaDeviceSynchronize();
    auto end = std::chrono::high_resolution_clock::now();
    
    std::chrono::duration<double, std::milli> diff = end - start;
    static int frame_count = 0;
    if (++frame_count % 30 == 0) {
        printf("CUDA Stitching time: %.2f ms\n", diff.count());
    }
}

// =========================================================================
// æ¨¡å¼ B: å®è½¦æ¨¡å¼ (Jetson NVStreamMux é‡‡é›†)
// =========================================================================
// =========================================================================
// æ¨¡å¼ B: å®è½¦æ¨¡å¼ (Jetson NVStreamMux é‡‡é›†)
// =========================================================================
#ifdef HAVE_JETSON_NVMM
static GstFlowReturn on_capture_sample(GstAppSink *appsink, gpointer user_data) {
    GstSample *sample = gst_app_sink_pull_sample(appsink);
    if (!sample) return GST_FLOW_OK;

    // ä» nvstreammux ä¸‹æ¸¸è·å–çš„æ˜¯ NVMM Batch Buffer
    GstBuffer *batch_buffer = gst_sample_get_buffer(sample);
    
    // æˆ‘ä»¬å¿…é¡»æ„é€ ä¸€ä¸ªä¸´æ—¶çš„è¾“å‡º Buffer ä¾› adapter ä½¿ç”¨
    // ç”±äº nvbuffer_cuda_process_multi éœ€è¦ä¸€ä¸ª GstBuffer* out æ¥ map NvBufSurface
    // åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥å¤ç”¨ batch_buffer çš„ç»“æ„ï¼Œæˆ–è€…æ›´ç®€å•ç‚¹ï¼š
    // å› ä¸º nvbuffer_cuda_process_multi å®é™…ä¸Šå¹¶æ²¡ç”¨åˆ° out_buffer çš„æ•°æ®ï¼Œåªè¦å®ƒçš„ metadata æ˜¯å¯¹çš„ã€‚
    // ä¸ºäº†ç¨³å¦¥ï¼Œæˆ‘ä»¬åœ¨ Real Mode åˆå§‹åŒ–æ—¶åº”è¯¥åˆ›å»ºä¸€ä¸ªä¸“é—¨çš„ NVMM Output Bufferã€‚
    // ä½†ä¸ºç®€åŒ–ï¼Œæˆ‘ä»¬æš‚æ—¶å¤ç”¨ d_out çš„æ˜¾å­˜ï¼Œé€šè¿‡ä¸€ä¸ª Fake GstBuffer æˆ–è€…ç›´æ¥è®© adapter æ”¯æŒ d_out æŒ‡é’ˆã€‚
    
    // ä¿®æ­£ï¼šæˆ‘ä»¬åˆšæ‰ä¿®æ”¹ nvbuffer_cuda_process_multi å®ç°æ—¶ï¼Œå®ƒæ˜¯ä» out_buffer æå– d_outã€‚
    // è¿™é‡Œæˆ‘ä»¬å¤„äº Real Modeï¼Œç†æƒ³æµç¨‹æ˜¯ï¼š
    // Capture -> NvStreamMux -> AppSink -> (Callback) -> CUDA Stitch -> d_out (GPU) -> Signal
    
    // ä¸ºäº†è®©ä»£ç é€šè¿‡ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ª "NVMM Output Buffer"ã€‚
    // æˆ‘ä»¬å¯ä»¥åŠ¨æ€åˆ›å»ºä¸€ä¸ªã€‚
    // ä½†æ›´å¥½çš„åšæ³•æ˜¯ï¼šä¿®æ”¹ nvbuffer_cuda_process_multi æ¥å£ï¼Œè®©å®ƒæ¥å— uchar4* d_outã€‚
    // è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥ä¼ æˆ‘ä»¬åœ¨ main() é‡Œ malloc çš„ d_outã€‚
    
    // ç„¶è€Œ adapter å·²ç»åœ¨ .h é‡Œå®šæ­»äº†ã€‚æˆ‘ä»¬å¾—ç”¨å¤æ‚çš„ Buffer Wrap å—ï¼Ÿ
    // ä¸ï¼Œé€šè¿‡ NvBufSurfaceFromFd å¯ä»¥... è¿™å¤ªå¤æ‚äº†ã€‚
    
    // ğŸ’¡ æœ€ä½³æ–¹æ¡ˆï¼šæ—¢ç„¶ d_out å·²ç»åœ¨ GPU ä¸Šï¼Œè€Œä¸”æ˜¯ cudaMalloc çš„ (Pitch å¯èƒ½ä¸ç­‰äº NVMM Pitch)ã€‚
    // æˆ‘ä»¬åœ¨ Capture Thread é‡Œç›´æ¥ä» batch_buffer è·å– 4 ä¸ªè¾“å…¥æŒ‡é’ˆï¼Œ
    // ç„¶åè°ƒç”¨ stitching_process è¾“å‡ºåˆ°å…¨å±€ d_outã€‚
    // adapter çš„ nvbuffer_cuda_process_multi å…¶å®æ˜¯ç»™å…¨ GStreamer ç®¡é“ç”¨çš„ã€‚
    // åœ¨è¿™é‡Œæˆ‘ä»¬æ˜¯ AppSinkï¼Œæˆ‘ä»¬å·²ç»æ‹¿åˆ°äº† raw bufferã€‚
    
    GstMapInfo map;
    gst_buffer_map(batch_buffer, &map, GST_MAP_READ);
    NvBufSurface *surf = (NvBufSurface *)map.data;
    
    // æ­¤æ—¶ surf->numFilled åº”è¯¥æ˜¯ 4
    if (NvBufSurfaceMap(surf, -1, -1, NVBUF_MAP_READ) == 0) {
        NvBufSurfaceSyncForDevice(surf, -1, -1);
        
        std::vector<uchar4*> input_ptrs;
        // å‡è®¾ nvstreammux çš„ batch é¡ºåºå°±æ˜¯ camera é¡ºåº (0,1,2,3)
        // nvstreammux sink_0 -> cam 0, sink_1 -> cam 1 ...
        for (int i = 0; i < 4 && i < surf->numFilled; i++) {
            input_ptrs.push_back((uchar4*)surf->surfaceList[i].dataPtr);
        }
        
        if (input_ptrs.size() == 4) {
             // è¿™é‡Œçš„ Pitch æ˜¯é—®é¢˜ã€‚cudaMalloc çš„ d_out æ˜¯ç´§å‡‘çš„å—ï¼Ÿ
             // stitching_process æ¥å— out_pitchã€‚
             // å¯¹äº d_out (cudaMalloc), pitch = width * 4ã€‚
             auto start = std::chrono::high_resolution_clock::now();
             stitching_process(d_out, OUT_WIDTH * sizeof(uchar4), input_ptrs);
             cudaDeviceSynchronize();
             auto end = std::chrono::high_resolution_clock::now();
             
             std::chrono::duration<double, std::milli> diff = end - start;
             static int frame_count_real = 0;
             if (++frame_count_real % 30 == 0) {
                 printf("Real-mode CUDA Stitching time: %.2f ms\n", diff.count());
             }
             
             // å”¤é†’ RTSP æ¨æµçº¿ç¨‹ï¼Œå¹¶è®°å½•é‡‡é›†å¼€å§‹æ—¶é—´
             {
                 std::lock_guard<std::mutex> lock(g_frame_mutex);
                 g_has_new_frame = true;
                 g_capture_time = std::chrono::high_resolution_clock::now();
             }
             g_frame_cv.notify_one();
        }
        
        NvBufSurfaceUnMap(surf, -1, -1);
    }
    
    gst_buffer_unmap(batch_buffer, &map);
    gst_sample_unref(sample);
    return GST_FLOW_OK;
}
#endif

// =========================================================================
// RTSP Server å›è°ƒ (è´Ÿè´£æŠŠ d_out æ¨å‡ºå»)
// =========================================================================
static void on_rtsp_need_data(GstElement *appsrc, guint unused, gpointer user_data) {
    static GstClockTime timestamp = 0;

    auto e2e_start = std::chrono::high_resolution_clock::now();

    // 1. ç”Ÿæˆæˆ–è·å–æœ€æ–°å¸§
    if (is_simulation) {
        process_simulation_frame();
    } else {
        // Real Mode: Wait for `on_capture_sample` to update d_out
        std::unique_lock<std::mutex> lock(g_frame_mutex);
        if (g_frame_cv.wait_for(lock, std::chrono::milliseconds(100), []{ return g_has_new_frame; })) {
            g_has_new_frame = false;
            e2e_start = g_capture_time; // Start latency from camera capture
        } else {
            // Timeout or no frame, push a black frame or just skip? 
            // For now, let's just use what's in d_out.
        }
    }

    // 2. å°† d_out (GPU) æ‹·è´å› CPU å‘é€ç»™ RTSP (x264enc)
    GstBuffer *buffer = gst_buffer_new_allocate(nullptr, OUT_WIDTH * OUT_HEIGHT * 4, nullptr);
    GstMapInfo map;
    gst_buffer_map(buffer, &map, GST_MAP_WRITE);
    cudaMemcpy(map.data, d_out, OUT_WIDTH * OUT_HEIGHT * sizeof(uchar4), cudaMemcpyDeviceToHost);
    gst_buffer_unmap(buffer, &map);

    GST_BUFFER_PTS(buffer) = timestamp;
    GST_BUFFER_DURATION(buffer) = gst_util_uint64_scale_int(1, GST_SECOND, FPS);
    timestamp += GST_BUFFER_DURATION(buffer);

    GstFlowReturn ret;
    g_signal_emit_by_name(appsrc, "push-buffer", buffer, &ret);
    gst_buffer_unref(buffer);

    auto e2e_end = std::chrono::high_resolution_clock::now();
    std::chrono::duration<double, std::milli> e2e_diff = e2e_end - e2e_start;
    
    static int e2e_frame_count = 0;
    if (++e2e_frame_count % 30 == 0) {
        printf("End-to-End Latency: %.2f ms\n", e2e_diff.count());
    }
}

static void media_configure_cb(GstRTSPMediaFactory *factory, GstRTSPMedia *media, gpointer user_data) {
    GstElement *element = gst_rtsp_media_get_element(media);
    GstElement *appsrc = gst_bin_get_by_name(GST_BIN(element), "mysrc");
    if (appsrc) {
        g_signal_connect(appsrc, "need-data", G_CALLBACK(on_rtsp_need_data), nullptr);
        gst_object_unref(appsrc);
    }
    gst_object_unref(element);
}

static GstRTSPMediaFactory* create_rtsp_factory() {
    GstRTSPMediaFactory *factory = gst_rtsp_media_factory_new();
    // ç»Ÿä¸€ä½¿ç”¨ appsrcï¼Œæ— è®ºæ˜¯ Sim è¿˜æ˜¯ Realã€‚
    // è¿™è§£è€¦äº† RTSP ä¼ è¾“å±‚å’Œå›¾åƒç”Ÿæˆå±‚ã€‚
    char* launch_str = g_strdup_printf(
        "( appsrc name=mysrc is-live=true format=GST_FORMAT_TIME "
        "caps=\"video/x-raw,format=RGBA,width=%d,height=%d,framerate=%d/1\" ! "
        "videoconvert ! video/x-raw,format=I420 ! "
        "x264enc speed-preset=ultrafast tune=zerolatency bitrate=4000 ! "
        "rtph264pay name=pay0 pt=96 )",
        OUT_WIDTH, OUT_HEIGHT, FPS
    );

    gst_rtsp_media_factory_set_launch(factory, launch_str);
    g_free(launch_str);
    gst_rtsp_media_factory_set_shared(factory, TRUE);
    g_signal_connect(factory, "media-configure", G_CALLBACK(media_configure_cb), nullptr);
    return factory;
}

// =========================================================================
// ä¸»ç¨‹åº
// =========================================================================
int main(int argc, char *argv[]) {
    for (int i = 1; i < argc; i++) {
        if (std::string(argv[i]) == "--sim") is_simulation = TRUE;
    }

    signal(SIGINT, signal_handler);
    gst_init(&argc, &argv);
    cuda_init();

    printf("Searching for LUT...\n");
    const char* lut_path = "surround_view.binary";
    if (fopen(lut_path, "r") == nullptr) lut_path = "stitching/surround_view.binary";
    if (fopen(lut_path, "r") == nullptr) lut_path = "../stitching/surround_view.binary";
    
    if (!stitching_init(lut_path, OUT_WIDTH, OUT_HEIGHT, IN_WIDTH, IN_HEIGHT)) {
        printf("Error: Failed to load LUT from %s\n", lut_path);
        return -1;
    }

    cudaMalloc(&d_out, OUT_WIDTH * OUT_HEIGHT * sizeof(uchar4));
    if (is_simulation) {
        for(int i=0; i<4; i++) cudaMalloc(&d_ins[i], IN_WIDTH * IN_HEIGHT * sizeof(uchar4));
    } else {
#ifdef HAVE_JETSON_NVMM
        // Real Mode: Build Capture Pipeline
        // v4l2src x 4 -> nvvideoconvert -> nvstreammux -> appsink
        // Note: For simplicity, we hardcode camera devices and nvstreammux settings.
        // nvstreammux batch-size=4 width=1280 height=1080 batched-push-timeout=40000
        
        GString *launch = g_string_new("");
        g_string_append_printf(launch, "nvstreammux name=mux batch-size=4 width=%d height=%d batched-push-timeout=40000 live-source=1 ! "
                                       "video/x-raw(memory:NVMM),format=RGBA ! "
                                       "appsink name=sink emit-signals=true max-buffers=1 drop=true ", IN_WIDTH, IN_HEIGHT);
        
        // Append sources
        for(int i=0; i<4; i++) {
             // Assuming devices are video0, 1, 2, 3
             // Need nvvidconv to ensure format is compatible with mux sink
             // v4l2src -> nvvidconv -> mux.sink_i
            g_string_append_printf(launch, 
                "v4l2src device=%s ! video/x-raw,width=%d,height=%d,framerate=%d/1 ! "
                "nvvidconv ! video/x-raw(memory:NVMM),format=RGBA ! "
                "mux.sink_%d ", 
                DEFAULT_DEVICES[i], IN_WIDTH, IN_HEIGHT, FPS, i);
        }
        
        printf("Launching Capture Pipeline: %s\n", launch->str);
        GError *err = nullptr;
        g_capture_pipeline = gst_parse_launch(launch->str, &err);
        g_string_free(launch, TRUE);
        
        if (!g_capture_pipeline || err) {
            printf("Error creating capture pipeline: %s\n", err ? err->message : "Unknown");
            return -1;
        }
        
        GstElement *sink = gst_bin_get_by_name(GST_BIN(g_capture_pipeline), "sink");
        g_signal_connect(sink, "new-sample", G_CALLBACK(on_capture_sample), nullptr);
        gst_object_unref(sink);
        
        gst_element_set_state(g_capture_pipeline, GST_STATE_PLAYING);
#else
        printf("Error: Real Mode requires Jetson NVMM support.\n");
        return -1;
#endif
    }

    main_loop = g_main_loop_new(nullptr, FALSE);
    GstRTSPServer *server = gst_rtsp_server_new();
    gst_rtsp_server_set_service(server, "8554");

    GstRTSPMountPoints *mounts = gst_rtsp_server_get_mount_points(server);
    gst_rtsp_mount_points_add_factory(mounts, "/live", create_rtsp_factory());
    g_object_unref(mounts);

    if (gst_rtsp_server_attach(server, nullptr) == 0) return -1;

    g_print("\n====================================\n");
    g_print("RTSP Server: %s Mode\n", is_simulation ? "SIMULATION" : "REAL CAMERA");
    g_print("Stream URL: rtsp://<IP>:8554/live\n");
    g_print("====================================\n\n");

    g_main_loop_run(main_loop);

    cuda_cleanup();
    if (d_out) cudaFree(d_out);
    for(int i=0; i<4; i++) if (d_ins[i]) cudaFree(d_ins[i]);
    
    return 0;
}
